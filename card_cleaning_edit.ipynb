{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "from fastparquet import ParquetFile\n",
    "from itertools import chain\n",
    "import re\n",
    "from addr_dict import state_dict, substate_dict\n",
    "from stop_word_list import stop_words_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_name_col = ['MER_NAME','CARD_USE_HIS']\n",
    "\n",
    "address_cols = ['MER_ADDR'] \n",
    "phone_col = 'MER_MSISDN'\n",
    "source = 'MEUMS_COLL_CARD_MER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_stopwords(s, stop_words_lst):\n",
    "    \"\"\"Clean strings by removing unwanted stopwords.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : string. string to delete stopwords\n",
    "\n",
    "    stop_words_lst : list. list of stopwords \n",
    "\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "\n",
    "    stop_words_lst = [\"(주)\", \"(유)\", \"(사)\", \"(의)\", \"(재)\",\n",
    "                    \"주식회사\", \"유한회사\", \"사단법인\", \"의료법인\", \"재단법인\",\n",
    "                    \"(사단)\", \"(유한)\", \"(의료)\", \"(법인)\", \"(재단)\",\n",
    "                    \"(주식회사)\", \"(유한회사)\", \"(사단법인)\", \"(의료법인)\", \"(재단법인)\", \n",
    "                    \"[아이행복]\", \"온누리상품권\", \"무이자\"]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "    \"\"\"\n",
    "\n",
    "    for sw in stop_words_lst:\n",
    "        # delete the stopword when store name starts with the stopword\n",
    "        s = s.replace(sw, ' ')\n",
    "#         if s.startswith(sw):\n",
    "#             s = s.replace(sw, \"\")\n",
    "\n",
    "#         # delete the stopword when store name starts with the stopword\n",
    "#         elif s.endswith(sw):\n",
    "#             s = s.replace(sw, \"\")\n",
    "\n",
    "#         # delete the stopword when store name has the stopword (with space)\n",
    "#         else: \n",
    "#             s = ' '.join([w for w in s.split() if w not in stop_words_lst])           \n",
    "\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_by(s, by_whitespace, by_none):\n",
    "    \"\"\"Replace something by whitespace or none.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : series. series of string to delete something\n",
    "\n",
    "    by_whitespace : regex or string to replace by single whitespace\n",
    "    \n",
    "    by_none : regex or string to replace by none.\n",
    "\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    by_whitespace : r'[\\(\\)\\[\\]]' ==> replace brasekets like (), [] to single whitespace.\n",
    "    by_none : r'[\\-\\_\\]' ==> delete  -, _ .\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    series\n",
    "    \"\"\"\n",
    "\n",
    "    if by_whitespace:\n",
    "        s = s.str.replace(by_whitespace, ' ')\n",
    "        # example : r'[\\(\\)\\[\\]]'\n",
    "\n",
    "    if by_none:\n",
    "        s = s.str.replace(by_none, '')\n",
    "        # example : r'[\\-\\_\\]'\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove(s, bw_brackets = True, double_space = True, single_space = False):\n",
    "    \"\"\"\n",
    "    Clean words between something.\n",
    "    \"\"\"\n",
    "\n",
    "    if bw_brackets:\n",
    "        s = s.replace(r'(\\[.*?\\]|\\(.*?\\)|\\{.*?\\})', '')\n",
    "\n",
    "    if double_space:\n",
    "        s = s.replace(r'\\s\\s+', ' ')\n",
    "\n",
    "    if single_space:\n",
    "        s = s.replace(r'\\s', '')\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_words_lst_maker(df,col_name):\n",
    "    \n",
    "    match=[]\n",
    "    match_list=[]\n",
    "    for idx in list(df[col_name]):\n",
    "        match.append(re.findall(r'^(\\[.*?\\]|\\(.*?\\)|\\{.*?\\})',idx))\n",
    "            \n",
    "    for idx in match:\n",
    "        for i in idx:\n",
    "            match_list.append(i)\n",
    "        \n",
    "    match_list=list(set(match_list))\n",
    "    \n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def del_start_end_void(s):\n",
    "    s=s.strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_name(df, co_name_col, stop_words_lst):\n",
    "    s = datetime.datetime.now()\n",
    "    \n",
    "    df[co_name_col + '_new'] = df[co_name_col].apply(delete_stopwords, stop_words_lst = stop_words_lst)\n",
    "    df[co_name_col + '_new'] = replace_by(df[co_name_col + '_new'], by_whitespace=r'[\\(\\[]',by_none=r'[\\)\\]]')\n",
    "    df[co_name_col + '_new'] = remove(df[co_name_col + '_new'], bw_brackets=False, double_space=True)\n",
    "    \n",
    "    df[co_name_col + '_new'] = df[co_name_col + '_new'].apply(del_start_end_void)\n",
    "    \n",
    "    df[co_name_col + '_yn'] = df[co_name_col] != df[co_name_col + '_new']\n",
    "    \n",
    "    print(datetime.datetime.now()-s, \"time spent to preprocess name column\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[df['CARD_USE_HIS'].str.contains(r'\\.\\.\\.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_processed_result(source_column, n_of_ex):\n",
    "    new_cols = [i for i in df.columns if i.startswith(source_column)]\n",
    "    print(\"Preprocessing source columns \", source_column)\n",
    "    print(\"# of records changed : \", df[source_column + '_yn'].sum())\n",
    "    try: \n",
    "        print(\"Examples:\")\n",
    "        display(df.loc[(df[source_column + '_yn'] == True), new_cols].sample(n_of_ex))\n",
    "    except ValueError:\n",
    "        print(\"No example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_addr_part1(addr):\n",
    "    \"\"\"\n",
    "    Get state, a substate, else, and detail part from an address.\n",
    "\n",
    "    :param addr: series.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # seperate address by comma(,)\n",
    "    if len(addr.split(\",\")) >= 2:\n",
    "        addr_main = addr.split(\",\")[0]\n",
    "        addr_detail = \" \".join(addr.split(\",\")[1:])\n",
    "\n",
    "    else:\n",
    "        addr_main = addr\n",
    "        addr_detail = ''\n",
    "\n",
    "    return addr_main, addr_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_addr_part2(addr_main):\n",
    "\n",
    "    # main 파트의 첫 번째 단어를 가져온다.\n",
    "    if len(addr_main.split()) >= 2:\n",
    "        addr_state = addr_main.split()[0]\n",
    "        addr_substate = addr_main.split()[1]\n",
    "        if len(addr_main.split()) >= 3:\n",
    "            addr_else = \" \".join(addr_main.split()[2:])\n",
    "        else:\n",
    "            addr_else = ''\n",
    "\n",
    "    else:\n",
    "        addr_state = addr_main\n",
    "        addr_substate = ''\n",
    "        addr_else =  ''\n",
    "\n",
    "    return addr_state, addr_substate, addr_else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_state(state_col):\n",
    "    state_col_new = state_col.copy()\n",
    "\n",
    "    # Change state name to official name\n",
    "    for state in state_dict.keys():\n",
    "        condition = state_col.isin(state_dict[state])\n",
    "        print(state, condition.sum())\n",
    "        ids_under_contion = state_col.loc[condition].index\n",
    "        state_col_new.loc[state_col_new.index.isin(ids_under_contion)] = state\n",
    "    \n",
    "#     print(state_col_new.unique())\n",
    "        \n",
    "    return state_col_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_blocks(df,address_cols):\n",
    "    \n",
    "    # address_cols is list \n",
    "    ad_col=address_cols[0]\n",
    "    df['block1'] = None #block1 default is 'None'\n",
    "    \n",
    "    \n",
    "    condition = (df[ad_col+'_state'].isin(list(state_dict.keys()))) & (df[ad_col+'_state'] != '세종특별자치시')\n",
    "    df.loc[condition, 'block1'] = df.loc[condition, ad_col+'_state']\n",
    "\n",
    "    condition = (df[ad_col+'_state'] == '세종특별자치시')\n",
    "    df['block1'] = df['block1'].mask(condition, '세종특별자치시')\n",
    "\n",
    "    df['block1'] = df['block1'].mask(df['block1'].isnull(), 'NoBlock1')\n",
    "    \n",
    "    df['block2'] = None #block2 default is 'None'\n",
    "    \n",
    "    #only use addr\n",
    "    #주소 list를 만들때 이 함수를 고려하여 만들어야함.\n",
    "    \n",
    "    \n",
    "    #Blocking step 1 : for POIs that have standardized substate name from ADDR and are not located in Sejong\n",
    "    condition = (df[ad_col+'_substate'].isin(list(chain.from_iterable(substate_dict.values())))) & (df[ad_col+'_state'] != '세종특별자치시')\n",
    "    df.loc[condition, 'block2'] = df.loc[condition, ad_col+'_substate']\n",
    "    \n",
    "    # Blocking step 2 : for POIs that are located in Sejong\n",
    "    condition = (df[ad_col+'_state'] == '세종특별자치시')\n",
    "    df['block2'] = df['block2'].mask(condition, '세종특별자치시')\n",
    "    \n",
    "    df['block2'] = df['block2'].mask(df['block2'].isnull(), 'NoBlock2')\n",
    "    \n",
    "    print(\"Finished blocking step 2.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_cols = ['SOURCE', 'SOURCE_ID', 'REG_DT', \n",
    "                  'MER_NAME_new','CARD_USE_HIS_new', 'block1', 'block2', 'MER_ADDR_new', 'MER_ADDR_else', \n",
    "                  'MER_MSISDN_new', 'PROCESSED_DT']\n",
    "\n",
    "output_cols = ['SOURCE', 'SOURCE_ID', 'SOURCE_UPT_DT', \n",
    "                   'CO_NAME_new','HIS_NAME_new','block1', 'block2', 'ADDR_new', 'ADDR_else', \n",
    "                   'REP_PHONE_NUM_new','PROCESSED_DT']\n",
    "\n",
    "output_table = \"ci_dev.PROCESSED_CARD_LOGIN_recleaning\"\n",
    "\n",
    "co_name_col = ['MER_NAME','CARD_USE_HIS']\n",
    "address_cols = ['MER_ADDR'] \n",
    "phone_col = 'MER_MSISDN'\n",
    "source = 'MEUMS_COLL_CARD_MER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7f979ae2dcc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_db.execute(\"DROP TABLE {}\".format(output_table))\n",
    "output_db.execute(\"CREATE TABLE {}\".format(output_table)+\n",
    "                  \" (SOURCE VARCHAR(30), SOURCE_ID INT , SOURCE_UPT_DT VARCHAR(50), \"+ \n",
    "                   \" CO_NAME_new VARCHAR(70), \" +\n",
    "                   \" HIS_NAME_new VARCHAR (70), \"\n",
    "                   \" block1 VARCHAR(35), block2 VARCHAR(35), \"+\n",
    "                   \" ADDR_new VARCHAR(1000), ADDR_else VARCHAR(1000), \"+\n",
    "                   \" REP_PHONE_NUM_new VARCHAR(50), PROCESSED_DT VARCHAR(50), PRIMARY KEY(SOURCE,SOURCE_ID),\"+\n",
    "                   \" KEY first_index (block1,block2))\"+\n",
    "                   \" CHARACTER SET utf8 COLLATE utf8_unicode_ci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_db_in_chunk(input_data, input_cols, output_db, output_table, output_cols, chunk_size):\n",
    "    s = datetime.datetime.now()\n",
    "    t = len(input_data)\n",
    "    max_chunk = t // chunk_size +1\n",
    "\n",
    "    for idx, i in enumerate(range(0, t, chunk_size)):\n",
    "        output_db.dispose()\n",
    "        records = tuple(tuple(row) for row in input_data.loc[i:i+chunk_size, input_cols].values)\n",
    "        insert_query = \"INSERT INTO {} {} VALUES (%s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s)\".format(output_table, tuple(output_cols))\n",
    "        insert_query = insert_query.replace(\"'\",\"\")\n",
    "        try:\n",
    "            output_db.execute(insert_query, records)\n",
    "        except sqlalchemy.exc.IntegrityError:\n",
    "            write_to_db_in_piece(input_data.loc[i:i+chunk_size], input_cols, output_db, output_table, output_cols)\n",
    "        \n",
    "        print(\"Chunk\", idx +1, \"/\", max_chunk, \": \", i, \"to \", i+chunk_size, \"records are inserted into {} table.\".format(output_table))\n",
    "        \n",
    "        \n",
    "    print(\"Time duration: \", datetime.datetime.now()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_db_in_piece(input_data, input_cols, output_db, output_table, output_cols):\n",
    "    s = datetime.datetime.now()\n",
    "    \n",
    "    for i,idx in input_data.iterrows():\n",
    "        output_db.dispose()\n",
    "        \n",
    "        records = list(row for row in idx[input_cols])\n",
    "        insert_query = \"INSERT INTO {} {} VALUES (%s, %s, %s, %s,%s, %s, %s, %s, %s, %s, %s)\".format(output_table, tuple(output_cols))\n",
    "        insert_query = insert_query.replace(\"'\",\"\")\n",
    "                \n",
    "        try:\n",
    "            output_db.execute(insert_query, tuple(records))\n",
    "        except sqlalchemy.exc.IntegrityError:\n",
    "            update_str= \" SET \" + \" , \".join(\" {} = %s \".format(n) for n in output_cols )\n",
    "            source_id = output_cols[1]\n",
    "            source = output_cols[0]\n",
    "            update_query = (\"UPDATE {} {} where {} = {} and {} = '{}' \"\n",
    "                            .format(output_table,update_str,source_id,idx[source_id],source,idx[source]))\n",
    "            \n",
    "            output_db.execute(update_query,idx[input_cols])\n",
    "            \n",
    "            \n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"10000 piece n= \", i/1000 , \"records are inserted into {} table.\".format(output_table))\n",
    "        \n",
    "        \n",
    "    print(\"Time duration: \", datetime.datetime.now()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": []
    }
   ],
   "source": [
    "on_off_line_df=pd.read_sql('select * from ci_dev.CARD_LOGIN_MER_TYPE_ONOFF',output_db)\n",
    "on_off_list=on_off_line_df[on_off_line_df['variable']=='Offline']['MER_TYPE'].values.tolist()\n",
    "n_df=pd.read_sql('select count(1) from eums.MEUMS_COLL_CARD_MER ',input_db)\n",
    "range_n=n_df['count(1)'].values.tolist()[0]\n",
    "\n",
    "for idx in range(0,(int)(range_n/10000)+1): #\n",
    "    df=pd.read_sql('select * from eums.MEUMS_COLL_CARD_MER limit %d,10000'%(idx*10000),input_db)\n",
    "   \n",
    "    df = df.mask(df.isna(), 'None')\n",
    "    df = df[~ (df['MER_NAME'].str.contains(\"개인택시\") & ~df['MER_NAME'].str.contains(\"충전소\"))]\n",
    "    \n",
    "    df=df[df['MER_TYPE'].isin(on_off_list)]\n",
    "    df=df[~(df['CARD_COMP']=='LOTTE_CARD')]\n",
    "    \n",
    "    df['MER_ADDR']=df['MER_ADDR'].str.replace(r'\\(.*\\)$','')\n",
    "    \n",
    "    #stop_word_add=stop_words_lst_maker(df,co_name_col)\n",
    "    \n",
    "    #for idx in stop_word_add:\n",
    "    #    stop_words_lst.append(idx)\n",
    "    #stop_words_lst=list(set(stop_words_lst))\n",
    "    \n",
    "    #print(stop_words_lst)\n",
    "    \n",
    "    for a in address_cols:\n",
    "        s = datetime.datetime.now()\n",
    "        \n",
    "        #preprocessing\n",
    "    \n",
    "    # ready\n",
    "        new = [a + s for s in ['_main', '_detail', '_state', '_substate', '_else', '_quality']]\n",
    "    \n",
    "     # default quality is bad\n",
    "        df[new[5]] = \"bad\"\n",
    "    \n",
    "    # mark records don't have value\n",
    "        df[new[5]] = df[new[5]].mask(((df[a] == '') | (df[a] == ' ') | (df[a] == 'None')), 'NoAddress')\n",
    "    \n",
    "    # split by ','\n",
    "        df[new[0]], df[new[1]] = zip(*df[a].apply(split_addr_part1))\n",
    "        print(a, \"column is splitted into \", new[:2], \" Time duration:\", datetime.datetime.now()-s)\n",
    "    \n",
    "    # split by ''\n",
    "        df[new[2]], df[new[3]], df[new[4]] = zip(*df[new[0]].apply(split_addr_part2))\n",
    "        print(a + \"_main\", \"column is splitted into\", new[2:-1], \"Time duration:\", datetime.datetime.now()-s)\n",
    "    \n",
    "    # standardize state column\n",
    "        df[new[2]] = standardize_state(df[new[2]])\n",
    "        df[new[5]] = df[new[5]].mask(df[new[2]].isin(list(state_dict.keys())), 'standardized')\n",
    "        print((df[new[5]] == 'standardized').sum(), \"are standardized in \", new[2], \"column. Time duration:\", datetime.datetime.now()-s)\n",
    "    \n",
    "    # assemble to make new addr column\n",
    "        df[a + '_new'] = df[new[2]] + ' '+ df[new[3]]+ ' ' + df[new[4]]\n",
    "    \n",
    "    #final preprocessing\n",
    "        df[a+'_new'] = remove(df[a+'_new'], bw_brackets= True, double_space= True, single_space= False)\n",
    "    \n",
    "    \n",
    "        df[a + '_yn'] = df[a] != df[a + '_new']\n",
    "    ##\n",
    "    \n",
    "    for kda in co_name_col:    \n",
    "        df = preprocess_name(df, kda, stop_words_lst)\n",
    "    \n",
    "    \n",
    "    s = datetime.datetime.now()\n",
    "    df[phone_col+'_new'] = df[phone_col]\n",
    "    df[phone_col + '_new'] =df[phone_col + '_new'].str.replace(r'[^0-9|^~]','')\n",
    "\n",
    "    df[phone_col + '_yn'] = df[phone_col] != df[phone_col + '_new']\n",
    "    print(datetime.datetime.now()-s, \"time spent.\")\n",
    "    print(df[phone_col+'_new'])\n",
    "    df=assign_blocks(df,address_cols)\n",
    "    \n",
    "    df['SOURCE'] = source\n",
    "    df.columns.values[0] = 'SOURCE_ID'\n",
    "    df['PROCESSED_DT'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['REG_DT'] =  df['REG_DT'].astype(str)\n",
    "    \n",
    "    write_to_db_in_chunk(df, input_cols, output_db, output_table, output_cols,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
