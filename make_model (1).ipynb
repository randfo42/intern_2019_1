{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier , ExtraTreesClassifier, GradientBoostingClassifier ,BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score,KFold\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score, recall_score,roc_curve, auc,make_scorer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초기 설정들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stat_test_array는 사용될 features지만, 원본에서 column이 다시 계산되어 사용될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set_one_hot_incoder는 초기 False로 설정 되어야 함 (추후 incode시 같은 값을 가지기 위해)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scoring : precision이 best인 것을 gridserchCV에서 고름. refit 설정 'Precision'으로 설정 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_array=['CO_mean','RE_mean','AD_mean','RO_mean'] # 사용할 column\n",
    "set_one_hot_incoder=False\n",
    "enc=OneHotEncoder(handle_unknown='ignore')\n",
    "dev_db = create_engine(\"mysql+pymysql://*/ci_dev?charset=utf8mb4\", encoding = 'utf8' ,\n",
    "                       pool_size=20,pool_recycle=3600,connect_args={'connect_timeout':1000000})\n",
    "scoring = {'Precision': make_scorer(precision_score)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_to_db_for_statistic(db,mean_table,label_table):\n",
    "    query=(\"\"\" select A.*,B.label \"\"\"+\n",
    "            \"\"\" from %s A \"\"\"%(mean_table)+\n",
    "            \"\"\" INNER JOIN %s B \"\"\"%(label_table)+\n",
    "            \"\"\" on A.SOURCE_ID_1 = B.SOURCE_ID_1 and A.SOURCE_ID_2=B.SOURCE_ID_2 \"\"\"+\n",
    "            #\"\"\" and A.SOURCE_1=B.SOURCE_1 \"\"\"+ #and A.source_2=B.source_2\"\"\"+\n",
    "            \"\"\" where B.label !=2 and B.source_1!=B.source_2 \"\"\") #and B.source_1!=B.source_2\n",
    "    res_df=pd.read_sql_query(query,db)\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best 알고리즘을 골라 다시 계산하여 column을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set_df_cleaning(df):\n",
    "    label_col=list(df.columns)\n",
    "    label_col=[x for x in label_col if x[0:2]=='CO' or x[0:2]=='RE' or x[0:2]=='AD' or x[0:2]=='RO'] \n",
    "    label_col.remove('COMPUTED_DT')\n",
    "\n",
    "    new_label_col=[]\n",
    "    for idx in label_col:\n",
    "        if idx[-3:]=='_qg' or idx[-3:]=='_jr' or idx[-3:]=='cos' or idx[-3:]== '_sw' or idx[-3:]=='lcs':\n",
    "            new_label_col.append(idx)\n",
    "\n",
    "    co=[x for x in new_label_col if x[0:2]=='CO'] \n",
    "    re=[x for x in new_label_col if x[0:2]=='RE'] \n",
    "    ad=[x for x in new_label_col if x[0:2]=='AD']\n",
    "    ro=[x for x in new_label_col if x[0:2]=='RO']\n",
    "\n",
    "    co_list=list(df[co].mean(axis=1))\n",
    "    re_list=list(df[re].mean(axis=1))\n",
    "    ad_list=list(df[ad].mean(axis=1))\n",
    "    ro_list=list(df[ro].mean(axis=1))\n",
    "\n",
    "    res_df=df.copy()\n",
    "\n",
    "    res_df['CO_mean']=co_list\n",
    "    res_df['RE_mean']=re_list\n",
    "    res_df['AD_mean']=ad_list\n",
    "    res_df['RO_mean']=ro_list\n",
    "    \n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe에서 x값을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set(df):\n",
    "    global set_one_hot_incoder\n",
    "    global stat_test_array\n",
    "\n",
    "    if 'CO_mean' not in df.columns.values.tolist():\n",
    "        df=make_set_df_cleaning(df)\n",
    "\n",
    "    \n",
    "    each_len=1\n",
    "\n",
    "    CO_NAME_l=[]\n",
    "    REP_PHONE_l=[]\n",
    "    ADDR_l=[]\n",
    "    ROAD_ADDR_l=[]\n",
    "\n",
    "    source_o=[]\n",
    "    \n",
    "    for idx in list(df['pair_source']):\n",
    "        source_o.append([idx])\n",
    "\n",
    "\n",
    "    if set_one_hot_incoder==False:\n",
    "        enc.fit(source_o)\n",
    "        set_one_hot_incoder=True\n",
    "\n",
    "    source=enc.transform(source_o).toarray()\n",
    "\n",
    "    \n",
    "    for idx in stat_test_array:\n",
    "        \n",
    "        if idx[0:2]=='CO':\n",
    "            CO_NAME_l.append(list(df[idx]))\n",
    "        if idx[0:2]=='RE':\n",
    "            REP_PHONE_l.append(list(df[idx]))\n",
    "        if idx[0:2]=='AD':\n",
    "            ADDR_l.append(list(df[idx]))\n",
    "        if idx[0:2]=='RO':\n",
    "            ROAD_ADDR_l.append(list(df[idx]))\n",
    "\n",
    "\n",
    "    res_list=[]\n",
    "    for idx in range(0,len(CO_NAME_l[0])):\n",
    "\n",
    "        add=[]\n",
    "\n",
    "        for k in range(0,each_len):\n",
    "            add.append(CO_NAME_l[k][idx])\n",
    "        \n",
    "        for k in range(0,each_len):\n",
    "            add.append(REP_PHONE_l[k][idx])\n",
    "\n",
    "        if ROAD_ADDR_l[0][idx] is None:\n",
    "            for k in range(0,each_len):     \n",
    "               add.append(ADDR_l[k][idx])\n",
    "        elif math.isnan(ROAD_ADDR_l[0][idx]) :\n",
    "            for k in range(0,each_len):     \n",
    "               add.append(ADDR_l[k][idx])\n",
    "        else:\n",
    "            aver_a=0\n",
    "            aver_r=0\n",
    "            for k in range(0,each_len):\n",
    "                aver_a=aver_a+ADDR_l[k][idx]\n",
    "                aver_r=aver_r+ROAD_ADDR_l[k][idx]        \n",
    "            if aver_a>aver_r:\n",
    "                for k in range(0,each_len):\n",
    "                    add.append(ADDR_l[k][idx])\n",
    "            else:\n",
    "                for k in range(0,each_len):\n",
    "                    add.append(ROAD_ADDR_l[k][idx])\n",
    "        \n",
    "        for k in source[idx]:\n",
    "            add.append(k)\n",
    "\n",
    "        res_list.append(add)\n",
    "\n",
    "   \n",
    "    for idx in range(0,len(res_list)):\n",
    "        for i in range(0,len(res_list[idx])): \n",
    "            if math.isnan(res_list[idx][i]):\n",
    "                res_list[idx][i]=0\n",
    "            \n",
    "\n",
    "    return res_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross vailidation 후 score 출력, \n",
    "\n",
    "### 75% data로 train 후 model, x_test, y_test 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_set(model,df):\n",
    "    start_time=time.time()\n",
    "\n",
    "    input_y= list(df['label'])\n",
    "    input_x= make_set(df)\n",
    "\n",
    "    input_x,test_x,input_y,test_y=train_test_split(input_x,input_y,\n",
    "                                 test_size=0.25,stratify=input_y,random_state=43)\n",
    "    \n",
    "\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('CV result')\n",
    "    \n",
    "    cv_score=[]\n",
    "    cv_precision=[]\n",
    "    cv_recall=[]\n",
    "    \n",
    "    \n",
    "    cv= KFold(5,shuffle=True,random_state=43)\n",
    "    for i,(idx_train,idx_test) in enumerate(cv.split(input_x,input_y)):\n",
    "        x_train_list=[]\n",
    "        y_train_list=[]\n",
    "        x_test_list=[]\n",
    "        y_test_list=[]\n",
    "\n",
    "        for idx in idx_train:\n",
    "            x_train_list.append(input_x[idx])\n",
    "            y_train_list.append(input_y[idx])\n",
    "\n",
    "        for idx in idx_test:\n",
    "            x_test_list.append(input_x[idx])\n",
    "            y_test_list.append(input_y[idx])\n",
    "            \n",
    "        x_train_list,y_train_list=SMOTEENN(random_state=0).fit_sample(x_train_list,y_train_list)\n",
    "\n",
    "        clf=model.fit(x_train_list,y_train_list)\n",
    "\n",
    "        add=model_scores(clf,x_test_list,y_test_list)\n",
    "            \n",
    "        cv_score.append(add[0])\n",
    "        cv_precision.append(add[1])\n",
    "        cv_recall.append(add[2])\n",
    "    \n",
    "    cv_score=np.array(cv_score)\n",
    "    cv_precision=np.array(cv_precision)\n",
    "    cv_recall=np.array(cv_recall)\n",
    "\n",
    "    \n",
    "    print('score : %0.3f (+/- %0.3f)'%(cv_score.mean(),cv_score.std()*2))\n",
    "    print('precision : %0.3f (+/- %0.3f)'%(cv_precision.mean(),cv_precision.std()*2))\n",
    "    print('score : %0.3f (+/- %0.3f)'%(cv_recall.mean(),cv_recall.std()*2))\n",
    "    \n",
    "    \n",
    "    input_x,input_y = SMOTEENN(random_state=0).fit_sample(input_x,input_y)\n",
    "\n",
    "    fin_clf=model.fit(input_x,input_y)\n",
    "    fin_score=fin_clf.score(test_x,test_y)\n",
    "\n",
    "    print('final_score')\n",
    "    print(fin_score)\n",
    "    res_time=time.time()-start_time\n",
    "    print('processing time : %0.2f'%(res_time))\n",
    "    return fin_clf,test_x,test_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model의 score 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores(model,test_x,test_y):\n",
    "    predict = model.predict(test_x)\n",
    "    \n",
    "    score = model.score(test_x,test_y)\n",
    "    precision = precision_score(test_y,predict)\n",
    "    recall = recall_score(test_y,predict)\n",
    "    \n",
    "    return score,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores):\n",
    "    print('score : %0.3f'%(scores[0]))\n",
    "    print('precision : %0.3f'%(scores[1]))\n",
    "    print('recall : %0.3f'%(scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model과 hyper parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(df):\n",
    "    \n",
    "    model= LogisticRegression(random_state=0,solver='liblinear')\n",
    "    \n",
    "    return statistic_set(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "\n",
    "    model = RandomForestClassifier(bootstrap=True,class_weight=None,max_depth=100,\n",
    "                                    n_estimators=2,random_state=43)\n",
    "    \n",
    "    return statistic_set(model,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBC(df):\n",
    "    model = GradientBoostingClassifier(n_estimators=200,learning_rate=1\n",
    "                                            ,max_depth=1,random_state=43)\n",
    "    \n",
    "    return statistic_set(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENSE(df):\n",
    "    model1=LogisticRegression(random_state=43)\n",
    "    model2=QuadraticDiscriminantAnalysis()\n",
    "    model3=GaussianNB()\n",
    "    ensemble = VotingClassifier(estimators=[('lr', model1), \n",
    "                                            ('qda', model2), \n",
    "                                            ('gnb', model3)], \n",
    "                                            voting='soft')\n",
    "    return statistic_set(ensemble,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECLF(df):\n",
    "    \n",
    "    rf = RandomForestClassifier(bootstrap=True,class_weight=None, max_depth=100, n_estimators=2,random_state=43)\n",
    "    et = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=43)\n",
    "    knn = KNeighborsClassifier()\n",
    "    svc = SVC(probability=True)\n",
    "    eclf = VotingClassifier(estimators=[('Random Forests', rf), \n",
    "                            ('Extra Trees', et), ('KNeighbors', knn), \n",
    "                            ('SVC', svc)], voting='soft')\n",
    "    \n",
    "    return statistic_set(eclf,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_RF(df):\n",
    "    rf = RandomForestClassifier(bootstrap=False,max_depth=200,n_estimators=2)\n",
    "    knn=KNeighborsClassifier(n_neighbors=500)\n",
    "    knn_rf=VotingClassifier(estimators=[('Random Forests',rf),('KNeigbors',knn)],voting='soft')\n",
    "    return statistic_set(knn_rf,df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warning 제거, 다시 띄울려면 default로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') # or set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_data_to_db_for_statistic(dev_db,'ci_dev.SIM_FEATURES_test','ci_dev.features_lable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_source(x):\n",
    "    if x=='intersecting_set':\n",
    "        return 'coname_SN'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pair_source']=df['pair_source'].apply(pair_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['coname_SN', 'phonenum_B'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pair_source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model score 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.952 (+/- 0.015)\n",
      "precision : 0.976 (+/- 0.011)\n",
      "score : 0.953 (+/- 0.034)\n",
      "final_score\n",
      "0.9575242718446602\n",
      "processing time : 0.35\n",
      "score : 0.958\n",
      "precision : 0.982\n",
      "recall : 0.956\n",
      "\n",
      "Random Forest\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.952 (+/- 0.021)\n",
      "precision : 0.981 (+/- 0.017)\n",
      "score : 0.948 (+/- 0.031)\n",
      "final_score\n",
      "0.9599514563106796\n",
      "processing time : 0.33\n",
      "score : 0.960\n",
      "precision : 0.984\n",
      "recall : 0.958\n",
      "\n",
      "GBC\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.962 (+/- 0.010)\n",
      "precision : 0.975 (+/- 0.015)\n",
      "score : 0.970 (+/- 0.016)\n",
      "final_score\n",
      "0.9660194174757282\n",
      "processing time : 1.26\n",
      "score : 0.966\n",
      "precision : 0.987\n",
      "recall : 0.963\n",
      "\n",
      "Logistic,QDA,GaussianNB\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.923 (+/- 0.061)\n",
      "precision : 0.975 (+/- 0.017)\n",
      "score : 0.912 (+/- 0.102)\n",
      "final_score\n",
      "0.933252427184466\n",
      "processing time : 0.46\n",
      "score : 0.933\n",
      "precision : 0.981\n",
      "recall : 0.921\n",
      "\n",
      "Random Forest, ExtraTree, Kneigbors\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.964 (+/- 0.012)\n",
      "precision : 0.979 (+/- 0.015)\n",
      "score : 0.968 (+/- 0.014)\n",
      "final_score\n",
      "0.9745145631067961\n",
      "processing time : 2.75\n",
      "score : 0.975\n",
      "precision : 0.988\n",
      "recall : 0.975\n",
      "\n",
      "random forest, Kneigbors\n",
      "-----------------------\n",
      "CV result\n",
      "score : 0.960 (+/- 0.005)\n",
      "precision : 0.974 (+/- 0.016)\n",
      "score : 0.968 (+/- 0.021)\n",
      "final_score\n",
      "0.9660194174757282\n",
      "processing time : 1.34\n",
      "score : 0.966\n",
      "precision : 0.987\n",
      "recall : 0.963\n"
     ]
    }
   ],
   "source": [
    "print('Logistic')\n",
    "log_res=logistic(df)\n",
    "print_scores(model_scores(log_res[0],log_res[1],log_res[2]))\n",
    "print('\\nRandom Forest')\n",
    "rf_res=random_forest(df)\n",
    "print_scores(model_scores(rf_res[0],rf_res[1],rf_res[2]))\n",
    "print('\\nGBC')\n",
    "gbc_res=GBC(df)\n",
    "print_scores(model_scores(gbc_res[0],gbc_res[1],gbc_res[2]))\n",
    "print('\\nLogistic,QDA,GaussianNB')\n",
    "LQG_res = ENSE(df)\n",
    "print_scores(model_scores(LQG_res[0],LQG_res[1],LQG_res[2]))\n",
    "print('\\nRandom Forest, ExtraTree, Kneigbors')\n",
    "REK_res = ECLF(df)\n",
    "print_scores(model_scores(REK_res[0],REK_res[1],REK_res[2]))\n",
    "print('\\nrandom forest, Kneigbors')\n",
    "RK_res = KNN_RF(df)\n",
    "print_scores(model_scores(RK_res[0],RK_res[1],RK_res[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict를 계산한뒤 df에 column을 추가해 df 반횐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_else_df(model,df):\n",
    "    \n",
    "    test_x= make_set(df)\n",
    "    predict = model.predict(test_x)\n",
    "    df_res=df.copy()\n",
    "    \n",
    "    df_res['predict']=predict\n",
    "    \n",
    "    return df_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict할 data 가져오기 (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_at_db_for_predict_else(db,mean_table,label_table):\n",
    "    query=(\"\"\" select A.*,B.label \"\"\"+\n",
    "            \"\"\" from %s A \"\"\"%(mean_table)+\n",
    "            \"\"\" left JOIN %s B \"\"\"%(label_table)+\n",
    "            \"\"\" on A.SOURCE_ID_1 = B.SOURCE_ID_1 and A.SOURCE_ID_2=B.SOURCE_ID_2 \"\"\"+\n",
    "            #\"\"\" and A.SOURCE_1=B.SOURCE_1 \"\"\"+ #and A.source_2=B.source_2\"\"\"+\n",
    "            \"\"\" where B.source_id_1 is null \"\"\") #and B.source_1!=B.source_2\n",
    "    res_df=pd.read_sql_query(query,db)\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=get_data_at_db_for_predict_else(dev_db,'ci_dev.SIM_FEATURES_test','ci_dev.features_lable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PROCESSED_CARD_LOGIN_recleaning'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['SOURCE_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pair_source']=pred_df['pair_source'].apply(pair_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1174783"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['coname_SN', 'phonenum_B'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['pair_source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=predict_else_df(REK_res[0],pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장될 column 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=res_df[['SOURCE_ID_1','SOURCE_ID_2','pair_source','predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle로 저장!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_pickle('../predicted_df/pred_{}.pkl'.format(datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
